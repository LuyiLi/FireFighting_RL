{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "import numpy as np\n",
    "\n",
    "# parameters for training\n",
    "GRAD_CLIP              = 30.0 # to clip gradients shown by tensorboard at 900 (30^2)\n",
    "RNN_SIZE               = 128\n",
    "GOAL_REPR_SIZE         = 12\n",
    "\n",
    "# def normalized_columns_initializer(std=1.0):\n",
    "#     def _initializer(shape, dtype=None):\n",
    "#         out = torch.randn(*shape).type(torch.FloatTensor)\n",
    "#         out *= std / (out**2).sum(0, keepdim=True).sqrt()\n",
    "#         return out\n",
    "#     return _initializer\n",
    "\n",
    "class ACNet(nn.Module):\n",
    "    def __init__(self, a_size, batch_size, trainer, learning_rate, TRAINING, GRID_SIZE):\n",
    "        super(ACNet, self).__init__()\n",
    "        # self.inputs = torch.nn.Parameter(torch.empty(1, 4, GRID_SIZE, GRID_SIZE))\n",
    "        # self.water_res = torch.nn.Parameter(torch.empty(1, 1))\n",
    "        # self.myinput = None  # You may need to transpose self.inputs here\n",
    "        # self.inputs = torch.zeros(batch_size, 4, GRID_SIZE, GRID_SIZE)\n",
    "        # self.water_res = torch.zeros(batch_size, 1)\n",
    "        # self.myinput = self.inputs\n",
    "        self.inputs = torch.zeros(batch_size, 4, GRID_SIZE, GRID_SIZE)\n",
    "        self.water_res = torch.zeros(batch_size, 1)\n",
    "\n",
    "\n",
    "        # Define ACNet layers\n",
    "        # 4 maps for each agent\n",
    "        self.conv1 = nn.Conv2d(4, RNN_SIZE // 4, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv1a = nn.Conv2d(RNN_SIZE // 4, RNN_SIZE // 4, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv1b = nn.Conv2d(RNN_SIZE // 4, RNN_SIZE // 4, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.conv2 = nn.Conv2d(RNN_SIZE // 4, RNN_SIZE // 2, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2a = nn.Conv2d(RNN_SIZE // 2, RNN_SIZE // 2, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2b = nn.Conv2d(RNN_SIZE // 2, RNN_SIZE // 2, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.conv3 = nn.Conv2d(RNN_SIZE // 2, RNN_SIZE - GOAL_REPR_SIZE, kernel_size=2, stride=1)\n",
    "        self.flat_size = (RNN_SIZE - GOAL_REPR_SIZE) * GRID_SIZE * GRID_SIZE  # Update this size based on your GRID_SIZE\n",
    "        self.flat_size = batch_size\n",
    "        self.fc0 = nn.Linear(1,GOAL_REPR_SIZE)\n",
    "        self.fc1 = nn.Linear(RNN_SIZE, RNN_SIZE)\n",
    "        self.fc2 = nn.Linear(RNN_SIZE, RNN_SIZE)\n",
    "        self.fc3 = nn.Linear(RNN_SIZE, RNN_SIZE)\n",
    "        # LSTM cell\n",
    "        self.lstm= nn.LSTM(RNN_SIZE, RNN_SIZE)\n",
    "        # Policy and value head\n",
    "        self.fc_policy = nn.Linear(RNN_SIZE, a_size)\n",
    "        self.fc_value = nn.Linear(RNN_SIZE, 1)\n",
    "        \n",
    "        # Define initial and current LSTM states\n",
    "        c_init = torch.zeros(1, RNN_SIZE, dtype=torch.float32)\n",
    "        h_init = torch.zeros(1, RNN_SIZE, dtype=torch.float32)\n",
    "        self.state_init = [c_init, h_init]\n",
    "        self.state_in = (torch.zeros(1, RNN_SIZE, dtype=torch.float32), torch.zeros(1, RNN_SIZE, dtype=torch.float32)) # (cell_state, hidden_state)\n",
    "\n",
    "        # self.policy, self.value, self.state_out, _ = self._build_net(self.myinput, self.water_res, RNN_SIZE, a_size)\n",
    "        # self.policy, self.value, self.state_out, _ = self._build_net(self.myinput, self.water_res, a_size)\n",
    "        self.policy, self.value, self.state_out, _ = self._build_net(self.inputs, self.water_res, a_size)\n",
    "\n",
    "        if TRAINING:\n",
    "            self.actions = torch.zeros(batch_size, dtype=torch.int64)\n",
    "            # print(self.actions.shape)\n",
    "            self.actions_onehot = F.one_hot(self.actions, a_size).type(torch.float32)\n",
    "            # print(self.actions_onehot.shape)\n",
    "            self.target_v = torch.zeros(batch_size, dtype=torch.float32)\n",
    "            self.advantages = torch.zeros(batch_size, dtype=torch.float32)\n",
    "            self.responsible_outputs = torch.sum(self.policy * self.actions_onehot, dim=1)\n",
    "\n",
    "            # Loss Functions\n",
    "            self.value_loss = 0.5 * torch.sum((self.target_v - self.value.view(-1))**2)\n",
    "            self.entropy = -0.01 * torch.sum(self.policy * torch.log(torch.clamp(self.policy, 1e-10, 1.0)))\n",
    "            self.policy_loss = -torch.sum(torch.log(torch.clamp(self.responsible_outputs, 1e-15, 1.0)) * self.advantages)\n",
    "            self.loss = self.value_loss + self.policy_loss - self.entropy\n",
    "\n",
    "            # Get gradients from local network using local losses and\n",
    "            # normalize the gradients using clipping\n",
    "            trainable_vars = list(self.parameters())\n",
    "            self.gradients = torch.autograd.grad(self.loss, trainable_vars, create_graph=True)\n",
    "            # self.var_norms = torch.norm(trainable_vars)\n",
    "            self.var_norms = torch.norm(torch.cat([v.view(-1) for v in trainable_vars]))\n",
    "            self.grad_norms = torch.nn.utils.clip_grad_norm_(self.gradients, GRAD_CLIP)\n",
    "            self.apply_grads = trainer(self.parameters(), lr=learning_rate)\n",
    "        \n",
    "        # Initialize model weights\n",
    "        self.apply(weights_init)\n",
    "\n",
    "        print(\"QAQ! The network is working!\")\n",
    "\n",
    "    def _build_net(self, inputs, water_res, a_size):\n",
    "        conv1 = F.relu(self.conv1(inputs))\n",
    "        conv1a = F.relu(self.conv1a(conv1))\n",
    "        conv1b = F.relu(self.conv1b(conv1a))\n",
    "        pool1 = self.pool1(conv1b)\n",
    "\n",
    "        conv2 = F.relu(self.conv2(pool1))\n",
    "        conv2a = F.relu(self.conv2a(conv2))\n",
    "        conv2b = F.relu(self.conv2b(conv2a))\n",
    "        pool2 = self.pool2(conv2b)\n",
    "\n",
    "        conv3 = self.conv3(pool2)\n",
    "        print(conv3.shape)\n",
    "\n",
    "        flat = torch.flatten(conv3, 1)\n",
    "        # flat = F.relu(conv3.view(-1, self.flat_size))\n",
    "        water_layer = F.relu(self.fc0(water_res))\n",
    "        print(flat.shape)\n",
    "        print(water_layer.shape)\n",
    "        hidden_input = torch.cat([flat, water_layer], dim=1)\n",
    "        print(hidden_input.shape)\n",
    "\n",
    "        h1 = F.relu(self.fc1(hidden_input))\n",
    "        h2 = F.relu(self.fc2(h1))\n",
    "        self.h3 = F.relu(self.fc3(h2 + hidden_input))\n",
    "\n",
    "        # # Recurrent network for temporal dependencies\n",
    "        # lstm_cell = nn.LSTMCell(RNN_SIZE, RNN_SIZE)\n",
    "        # rnn_in = h3.unsqueeze(0)\n",
    "        # step_size = inputs.size(0)\n",
    "        # lstm_out, state_out = lstm_cell(rnn_in, self.state_in)\n",
    "        # lstm_c, lstm_h = state_out\n",
    "        # state_out = (lstm_c[:1, :], lstm_h[:1, :])\n",
    "        # rnn_out = lstm_out.view(-1, RNN_SIZE)\n",
    "\n",
    "\n",
    "\n",
    "        # rnn_in = h3.unsqueeze(0)\n",
    "        # lstm_cell = nn.LSTMCell(input_size=RNN_SIZE, hidden_size=RNN_SIZE)\n",
    "        # packed_sequence = rnn_utils.pack_padded_sequence(rnn_in, lengths=[sequence_length], enforce_sorted=False)\n",
    "        # lstm_outputs, lstm_state = lstm_cell(packed_sequence)\n",
    "        # unpacked_sequence, _ = rnn_utils.pad_packed_sequence(lstm_outputs)\n",
    "        # lstm_c, lstm_h = lstm_state\n",
    "        # state_out = (lstm_c[:1, :], lstm_h[:1, :])\n",
    "        # rnn_out = unpacked_sequence.view(batch_size, -1)\n",
    "\n",
    "\n",
    "\n",
    "        # # Get the size of the input to the LSTMCell\n",
    "        # input_size = self.h3.size(1)\n",
    "        # lstm_cell = nn.LSTMCell(input_size=input_size, hidden_size=RNN_SIZE)\n",
    "        # c_init, h_init = self.state_in\n",
    "        # lstm_cell.bias_ih.data.fill_(0)  # assuming bias_ih is the bias for input gate\n",
    "        # lstm_cell.bias_hh.data.fill_(0)  # assuming bias_hh is the bias for hidden gate\n",
    "        # lstm_cell.weight_ih.data = torch.nn.init.xavier_normal_(lstm_cell.weight_ih.data)\n",
    "        # lstm_cell.weight_hh.data = torch.nn.init.orthogonal_(lstm_cell.weight_hh.data)\n",
    "        # lstm_out, new_state = lstm_cell(rnn_in, self.state_in)\n",
    "        # # Extract new LSTM state\n",
    "        # lstm_c, lstm_h = new_state\n",
    "        # state_out = (lstm_c.unsqueeze(0), lstm_h.unsqueeze(0))  # unsqueeze to add batch dimension\n",
    "        # # Reshape the LSTM output\n",
    "        # rnn_out = lstm_out.view(-1, RNN_SIZE)\n",
    "\n",
    "\n",
    "        # # Assuming RNN_SIZE is also the hidden size for LSTM\n",
    "        # rnn_in = self.h3.unsqueeze(0)  # Add a time dimension\n",
    "        # step_size = inputs.size(0)\n",
    "        # state_in = (torch.zeros(1, RNN_SIZE), torch.zeros(1, RNN_SIZE))\n",
    "        # # Perform dynamic LSTM operation\n",
    "        # lstm_outputs = []\n",
    "        # lstm_state = state_in\n",
    "        # for t in range(step_size):\n",
    "        #     lstm_state = self.lstm_cell(rnn_in[t], lstm_state)\n",
    "        #     lstm_outputs.append(lstm_state[0])\n",
    "        # # Convert the list of LSTM outputs to a PyTorch tensor\n",
    "        # lstm_outputs = torch.stack(lstm_outputs, dim=0)\n",
    "\n",
    "        # # Extract LSTM cell and hidden states\n",
    "        # lstm_c, lstm_h = lstm_state\n",
    "        # state_out = (lstm_c[:1, :], lstm_h[:1, :])\n",
    "\n",
    "        # # Reshape the LSTM outputs\n",
    "        # rnn_out = lstm_outputs.view(-1, RNN_SIZE)\n",
    "\n",
    "\n",
    "\n",
    "        # # Recurrent network for temporal dependencies\n",
    "        # lstm_cell = nn.LSTMCell(input_size=RNN_SIZE, hidden_size=RNN_SIZE)\n",
    "        # rnn_in = self.h3.unsqueeze(0)\n",
    "        # print(rnn_in.shape)\n",
    "        # # step_size = inputs.size(0)\n",
    "        # # packed_sequence = torch.nn.utils.rnn.pack_padded_sequence(rnn_in, [step_size], enforce_sorted=False)\n",
    "        # # lstm_outputs, lstm_state = lstm_cell(packed_sequence, self.state_in)\n",
    "        # # lstm_outputs, _ = torch.nn.utils.rnn.pad_packed_sequence(lstm_outputs)\n",
    "        # # lstm_c, lstm_h = lstm_state\n",
    "        # # state_out = (lstm_c[:1, :], lstm_h[:1, :])\n",
    "        # # rnn_out = lstm_outputs.view(-1, RNN_SIZE)\n",
    "        # lstm_out, lstm_state = lstm_cell(rnn_in, self.state_in)\n",
    "        # lstm_c, lstm_h = lstm_state\n",
    "        # # state_out = (lstm_c.unsqueeze(0), lstm_h.unsqueeze(0))\n",
    "        # state_out = (lstm_c[:1, :], lstm_h[:1, :])\n",
    "        # # rnn_out = lstm_out.squeeze(0)\n",
    "        # rnn_out = lstm_out.view(-1, RNN_SIZE)\n",
    "\n",
    "\n",
    "        rnn_in = self.h3.unsqueeze(0)\n",
    "        # TODO: Modify time step HERE.\n",
    "        # sequence_length = 1\n",
    "        # rnn_in = self.h3.unsqueeze(0).unsqueeze(0).expand(sequence_length, -1, -1)\n",
    "        lstm_out, lstm_state = self.lstm(rnn_in)\n",
    "        lstm_c, lstm_h = lstm_state\n",
    "        state_out = (lstm_c[:1, :], lstm_h[:1, :])\n",
    "        # rnn_out = lstm_out.squeeze(0)\n",
    "        rnn_out = lstm_out.view(-1, RNN_SIZE)\n",
    "\n",
    "\n",
    "        policy_layer = self.fc_policy(rnn_out)\n",
    "        policy = F.softmax(policy_layer, dim=1)\n",
    "        policy_sig = torch.sigmoid(policy_layer)\n",
    "        value = self.fc_value(rnn_out)\n",
    "\n",
    "        return policy, value, state_out, policy_sig\n",
    "    \n",
    "# Function for weights initialization\n",
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "        init.xavier_uniform_(m.weight.data)\n",
    "        init.constant_(m.bias.data, 0)\n",
    "    elif isinstance(m, nn.LSTM):\n",
    "        for param in m.parameters():\n",
    "            if len(param.shape) >= 2:\n",
    "                init.orthogonal_(param.data)\n",
    "            else:\n",
    "                init.constant_(param.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 116, 1, 1])\n",
      "torch.Size([3, 116])\n",
      "torch.Size([3, 12])\n",
      "torch.Size([3, 128])\n",
      "QAQ! The network is working!\n"
     ]
    }
   ],
   "source": [
    "# action size: 4 direction movements, stop, 4 direction spraying with short/long range, and go back to water supply station.\n",
    "a_size = 4 + 1 + 4 + 1\n",
    "trainer = torch.optim.SGD\n",
    "TRAINING = True\n",
    "GRID_SIZE = 11\n",
    "learning_rate=1e-4\n",
    "# agent_num\n",
    "agent_num = 3\n",
    "\n",
    "# __init__(self, scope, a, trainer, TRAINING, GRID_SIZE)\n",
    "net = ACNet(a_size, agent_num, trainer, learning_rate, TRAINING, GRID_SIZE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "course_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
