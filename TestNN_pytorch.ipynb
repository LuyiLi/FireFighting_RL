{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-27T10:07:48.221740103Z",
     "start_time": "2023-10-27T10:07:48.128129219Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from ACNet_pytorch import ACNet\n",
    "from ACNet_pytorch import ACNetLoss\n",
    "from FireFightingEnv import FFEnv\n",
    "\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize environment\n",
    "agent_num = 3\n",
    "env = FFEnv(agent_num=agent_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x1080 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "env.mapEnv.plotAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0.]\n",
      " [1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 1.]] \n",
      "\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]] \n",
      "\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]] \n",
      "\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]] \n",
      "\n",
      "10 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luyi/anaconda3/envs/me5418-sb3-test1/lib/python3.7/site-packages/ipykernel_launcher.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "obs = np.array(env.observe_space)\n",
    "\n",
    "# obstacle map of agent[0]\n",
    "print(obs[0, 0], \"\\n\")\n",
    "# fire map of agent[0]\n",
    "print(obs[0, 1], \"\\n\")\n",
    "# agent map of agent[0]\n",
    "print(obs[0, 2], \"\\n\")\n",
    "# flammable map of agent[0]\n",
    "print(obs[0, 3], \"\\n\")\n",
    "# reserved water of agent[0]\n",
    "print(obs[0, 4], \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 4, 11, 11)\n",
      "(3, 1)\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "inputs_raw = np.array(obs[:, :4])\n",
    "inputs = []\n",
    "for map in inputs_raw:\n",
    "    reshaped_map = [np.array(arr) for arr in map]\n",
    "    inputs.append(reshaped_map)\n",
    "inputs = np.array(inputs)\n",
    "print(inputs.shape)\n",
    "\n",
    "water_res = np.array(obs[:, 4]).reshape(-1,1)\n",
    "print(water_res.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QAQ! The network is working!\n"
     ]
    }
   ],
   "source": [
    "# action size: 4 direction movements, stop, 4 direction spraying with short/long range, and go back to water supply station.\n",
    "a_size = 4 + 1 + 4 + 1\n",
    "trainer = torch.optim.SGD\n",
    "TRAINING = True\n",
    "GRID_SIZE = 11\n",
    "# RNN_SIZE = 128\n",
    "learning_rate=1e-4\n",
    "agent_num = 3\n",
    "\n",
    "# __init__(self, scope, a, trainer, TRAINING, GRID_SIZE)\n",
    "net = ACNet(a_size, agent_num, trainer, learning_rate, TRAINING, GRID_SIZE)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate, weight_decay=0.0001)\n",
    "# FIXME: How to define loss_func\n",
    "loss_func = ACNetLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4, 11, 11])\n",
      "torch.Size([3, 1])\n"
     ]
    }
   ],
   "source": [
    "# 以下代码测试单次网络forward和Loss计算\n",
    "# 原本括号里面是np.int64,没太懂，求解释\n",
    "inputs_torch = torch.from_numpy(inputs.astype(np.float32))\n",
    "print(inputs_torch.shape)\n",
    "water_res_torch = torch.from_numpy(water_res.astype(np.float32))\n",
    "print(water_res_torch.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "torch.Size([3, 128])\n"
     ]
    }
   ],
   "source": [
    "outputs = net(inputs_torch, water_res_torch)\n",
    "policy = outputs[0]\n",
    "value = outputs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'target_v' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_168854/839399777.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# 困惑的是，actions, target_v, advantages如何更新在原始TensorFlow代码中并不明确（或者说pyz没找到xox）\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mactions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_v\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madvantages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'target_v' is not defined"
     ]
    }
   ],
   "source": [
    "# 计算loss\n",
    "# 困惑的是，actions, target_v, advantages如何更新在原始TensorFlow代码中并不明确（或者说pyz没找到xox）\n",
    "actions = 10\n",
    "loss = loss_func(policy, value, actions, target_v, advantages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luyi/anaconda3/envs/me5418-sb3-test1/lib/python3.7/site-packages/ipykernel_launcher.py:23: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    }
   ],
   "source": [
    "# 以下代码测试多次网络forward和Loss计算\n",
    "state = env.reset()\n",
    "episode_rollout = []\n",
    "iteration = 10\n",
    "\n",
    "actions, action_array = [],[]\n",
    "for i in range(3):\n",
    "    actions.append([[], []])\n",
    "    action_array.append(0)\n",
    "\n",
    "for t in range(iteration):\n",
    "    # 2 parameter to describe 1 action\n",
    "    # Direction:[0, 1, 2, 3, 4], moving or spraying:[0, 1]\n",
    "    for i, a in enumerate(actions):\n",
    "        a[0] = np.random.choice([0, 1, 2, 3, 4])\n",
    "        a[1] = np.random.choice([0, 1])\n",
    "\n",
    "        # encode action in action space\n",
    "        action_array[i] = a[0] * 2 + a[1]\n",
    "    \n",
    "    s1, rewards, done = env.step(actions)\n",
    "\n",
    "    state = np.array(state)\n",
    "    maps_raw = np.array(state[:, :4])\n",
    "    maps = []\n",
    "    for map in maps_raw:\n",
    "        reshaped_map = [np.array(arr) for arr in map]\n",
    "        maps.append(reshaped_map)\n",
    "    maps = np.array(maps)\n",
    "    # maps = maps_raw\n",
    "    \n",
    "    water = np.array(state[:, 4]).reshape(-1,1)\n",
    "    # water = np.array(state[:, 4])\n",
    "\n",
    "    episode_rollout.append([maps, water, np.array(action_array), rewards])\n",
    "    state = s1[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([30, 4, 11, 11])\n",
      "torch.Size([30, 1])\n",
      "torch.Size([30])\n",
      "torch.Size([30])\n"
     ]
    }
   ],
   "source": [
    "# batch_size, channel, map_size[0], map_size[1]\n",
    "inputs_torch    = torch.LongTensor(torch.from_numpy(np.array([item[0] for item in episode_rollout]).reshape(iteration*agent_num, 4, 11, 11).astype(np.int64)))\n",
    "# batch_size, water_reserved\n",
    "water_res_torch = torch.from_numpy(np.array([item[1] for item in episode_rollout]).reshape(iteration*agent_num, 1).astype(np.int64))\n",
    "# batch_size\n",
    "actions_torch   = torch.from_numpy(np.array([item[2] for item in episode_rollout]).reshape(iteration*agent_num).astype(np.int64))\n",
    "# batch_size\n",
    "rewards_torch   = torch.from_numpy(np.array([item[3] for item in episode_rollout]).reshape(iteration*agent_num).astype(np.float64))\n",
    "print(inputs_torch.shape)\n",
    "print(water_res_torch.shape)\n",
    "print(actions_torch.shape)\n",
    "print(rewards_torch.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "print(inputs_torch.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.utils.data as utils_dat\n",
    "# inputs_torch    = utils_dat.DataLoader(dataset=inputs_torch, batch_size=1, shuffle=True)\n",
    "# water_res_torch = utils_dat.DataLoader(dataset=water_res_torch, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "expected scalar type Long but found Float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-98-d1e1cdf50809>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs_torch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwater_res_torch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/course_env/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/ME5418_Git/FireFighting_RL/ACNet_pytorch.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, water_res)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;31m# def _build_net(self, inputs, water_res, a_size):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwater_res\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mconv1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/course_env/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/course_env/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/course_env/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    441\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    442\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 443\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: expected scalar type Long but found Float"
     ]
    }
   ],
   "source": [
    "# outputs = net(inputs_torch.to(torch.int64), water_res_torch.to(torch.int64))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
