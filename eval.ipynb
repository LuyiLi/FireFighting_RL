{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import FireFightingEnv as FFEnv\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "from collections import namedtuple, deque\n",
    "from itertools import count\n",
    "import torch.nn as nn\n",
    "import imageio\n",
    "\n",
    "# Test num is the number of run we trained to evaluate, as mentioned in our reports\n",
    "\n",
    "test_num=10\n",
    "\n",
    "# This 'eval' can evaluate DQN, Policy Gradiant, and ActorCritic\n",
    "# For DQN evaluation, please set model_name = ''\n",
    "# For Policy Gradient evaluation, please set model_name = 'PG'\n",
    "# For Actor Critic evaluation, please set model_name = 'AC'\n",
    "\n",
    "model_name = 'AC'\n",
    "\n",
    "# e.g. to test run8 of DQN, set: test_num = 8, model_name = ''\n",
    "\n",
    "if model_name == 'AC':\n",
    "    from ACNet_Real import ACNet\n",
    "else:\n",
    "    from ACNet_v1 import ACNet\n",
    "\n",
    "AGT_COUNT = 3\n",
    "GRID_SIZE = 5\n",
    "\n",
    "def test_model(policy_net, env, num_episodes=10):\n",
    "    policy_net.eval()  # 将模型设为评估模式\n",
    "    fire_frames = []\n",
    "    fire_agent_frames = []\n",
    "    env_frames = []\n",
    "\n",
    "    for i_episode in range(num_episodes):\n",
    "        state = env.reset()\n",
    "        total_reward = 0\n",
    "\n",
    "        while True:\n",
    "            # 对每个agent进行推断\n",
    "            actions = []\n",
    "            for s in state:\n",
    "                input = torch.from_numpy(s[0]).float().to(device)  # 将state转换为tensor\n",
    "                water_res = torch.tensor([[s[1]]]).float().to(device)\n",
    "                if model_name == 'AC':\n",
    "                    action_i, _ = policy_net(input.unsqueeze(0), water_res)\n",
    "                    action_i = action_i.max(1)[1].view(1, 1)\n",
    "                else:\n",
    "                    action_i = policy_net(input.unsqueeze(0), water_res).max(1)[1].view(1, 1)\n",
    "                action_int = action_i.item()\n",
    "                action = [action_int % 5, int(action_int / 5)]\n",
    "                actions.append(action)\n",
    "\n",
    "            # 执行动作\n",
    "            next_state, reward, done = env.step(actions)\n",
    "\n",
    "            # 更新总奖励\n",
    "            total_reward += sum(reward)\n",
    "\n",
    "            # 更新当前状态\n",
    "            state = next_state\n",
    "\n",
    "            fire_frames.append(env.mapEnv.figFire())\n",
    "            env_frames.append(env.mapEnv.figEnv())\n",
    "            fire_agent_frames.append(env.mapEnv.figFireAgent())\n",
    "            \n",
    "            \n",
    "            # 如果episode结束，则打印总奖励并退出循环\n",
    "            if done:\n",
    "                print(f\"Episode {i_episode + 1}, Total Reward: {total_reward}\")\n",
    "                imageio.mimsave('./results/gif/environment' + model_name + str(test_num) + '.gif', env_frames, duration=0.5)\n",
    "                # imageio.mimsave('./results/gif/fire.gif', fire_frames, duration=0.5)\n",
    "                imageio.mimsave('./results/gif/fire_agent' + model_name + str(test_num) + '.gif', fire_agent_frames, duration=0.5)\n",
    "                break\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ACNet(\n",
       "  (conv1): Conv2d(4, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv1a): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv1b): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2a): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2b): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv3): Conv2d(64, 116, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (fc0): Linear(in_features=1, out_features=12, bias=True)\n",
       "  (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (fc3): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (lstm): LSTM(128, 128, batch_first=True)\n",
       "  (fc_policy): Linear(in_features=128, out_features=10, bias=True)\n",
       "  (fc_value): Linear(in_features=128, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建环境\n",
    "env = FFEnv.FFEnv(3)  # 请用你实际使用的环境类来替代\n",
    "\n",
    "# 创建模型实例\n",
    "policy_net = ACNet(10, GRID_SIZE)  # 请用你实际使用的神经网络类来替代\n",
    "\n",
    "# 加载模型参数\n",
    "checkpoint = torch.load('./results/checkpoint/Run'+ model_name  + str(test_num) + '.pth')  # 请用你实际的模型文件路径来替代\n",
    "policy_net.load_state_dict(checkpoint)\n",
    "\n",
    "# 设置设备\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "policy_net.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1, Total Reward: -362.4500000000013\n"
     ]
    }
   ],
   "source": [
    "TEST_ALL = 1\n",
    "if(TEST_ALL):\n",
    "    test_model(policy_net, env, num_episodes=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_VIEW_SINGLE_STEP = 0\n",
    "if(TEST_VIEW_SINGLE_STEP):\n",
    "    policy_net.eval()  # 将模型设为评估模式\n",
    "\n",
    "    state = env.reset()\n",
    "    total_reward = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fire_agent_frames = []\n",
    "fire_agent_frames.append(env.mapEnv.figFireAgent())\n",
    "\n",
    "if(TEST_VIEW_SINGLE_STEP):\n",
    "    # 对每个agent进行推断\n",
    "    actions = []\n",
    "    for s in state:\n",
    "        input = torch.from_numpy(s[0]).float().to(device)  # 将state转换为tensor\n",
    "        water_res = torch.tensor([[s[1]]]).float().to(device)\n",
    "        if model_name == '':\n",
    "            action_i = policy_net(input.unsqueeze(0), water_res).max(1)[1].view(1, 1)\n",
    "        elif model_name == 'PG':\n",
    "            action_i = torch.argmax(policy_net(input.unsqueeze(0), water_res).max(1)[1].view(1, 1))\n",
    "        elif model_name == 'AC':\n",
    "            action_i, _ = policy_net(input.unsqueeze(0), water_res)\n",
    "            action_i = action_i.max(1)[1].view(1, 1)\n",
    "        else:\n",
    "            raise Exception\n",
    "        action_int = action_i.item()\n",
    "        action = [action_int % 5, int(action_int / 5)]\n",
    "        actions.append(action)\n",
    "    print(actions)\n",
    "    \n",
    "    # 执行动作\n",
    "    next_state, reward, done = env.step(actions)\n",
    "    # print(next_state)\n",
    "    print(reward)\n",
    "    env.mapEnv.plotAgent()\n",
    "    # env.mapEnv.plotAll()\n",
    "    env.mapEnv.plotFireMap()\n",
    "\n",
    "    fire_agent_frames.append(env.mapEnv.figFireAgent())\n",
    "\n",
    "    # 更新总奖励\n",
    "    total_reward += sum(reward)\n",
    "\n",
    "    # 更新当前状态\n",
    "    state = next_state\n",
    "\n",
    "    # 如果episode结束，则打印总奖励并退出循环\n",
    "    if done:\n",
    "        print(\"DONE\")\n",
    "        imageio.mimsave('fire_agent.gif', fire_agent_frames, duration=0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "me5418-sb3-test1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
